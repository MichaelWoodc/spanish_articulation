{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbed15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Whisper MEDIUM Model Analysis ===\n",
      "\n",
      "Model structure:\n",
      "  encoder: AudioEncoder - 305,680,384 parameters\n",
      "  decoder: TextDecoder - 456,641,536 parameters\n",
      "\n",
      "Encoder details:\n",
      "  Input dimensions: N/A\n",
      "  Number of blocks: 24\n",
      "  First block structure:\n",
      "    attn: 4,197,376 params\n",
      "    attn_ln: 2,048 params\n",
      "    mlp: 8,393,728 params\n",
      "    mlp_ln: 2,048 params\n",
      "\n",
      "Decoder details:\n",
      "  Output dimensions: N/A\n",
      "  Number of blocks: 24\n",
      "\n",
      "Memory requirements:\n",
      "  Total parameters: 762,321,920\n",
      "  Model size: 2908.03 MB\n",
      "  Estimated inference memory: 11632.11 MB (rough estimate)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "# First, define the model size\n",
    "MODEL_SIZE = \"medium\"  # or \"tiny\", \"base\", \"small\", \"large\"\n",
    "\n",
    "def comprehensive_model_analysis(model_size=\"medium\"):\n",
    "    \"\"\"Comprehensive analysis of Whisper model\"\"\"\n",
    "    model = whisper.load_model(model_size)\n",
    "    \n",
    "    print(f\"=== Whisper {model_size.upper()} Model Analysis ===\")\n",
    "    \n",
    "    # Model structure\n",
    "    print(f\"\\nModel structure:\")\n",
    "    for name, module in model.named_children():\n",
    "        num_params = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"  {name}: {type(module).__name__} - {num_params:,} parameters\")\n",
    "    \n",
    "    # Encoder details\n",
    "    if hasattr(model, 'encoder'):\n",
    "        encoder = model.encoder\n",
    "        print(f\"\\nEncoder details:\")\n",
    "        print(f\"  Input dimensions: {getattr(encoder, 'd_model', 'N/A')}\")\n",
    "        if hasattr(encoder, 'blocks'):\n",
    "            print(f\"  Number of blocks: {len(encoder.blocks)}\")\n",
    "            # Analyze first block\n",
    "            if len(encoder.blocks) > 0:\n",
    "                first_block = encoder.blocks[0]\n",
    "                print(f\"  First block structure:\")\n",
    "                for name, module in first_block.named_children():\n",
    "                    params = sum(p.numel() for p in module.parameters())\n",
    "                    print(f\"    {name}: {params:,} params\")\n",
    "    \n",
    "    # Decoder details  \n",
    "    if hasattr(model, 'decoder'):\n",
    "        decoder = model.decoder\n",
    "        print(f\"\\nDecoder details:\")\n",
    "        print(f\"  Output dimensions: {getattr(decoder, 'd_model', 'N/A')}\")\n",
    "        if hasattr(decoder, 'blocks'):\n",
    "            print(f\"  Number of blocks: {len(decoder.blocks)}\")\n",
    "    \n",
    "    # Memory requirements\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**2)\n",
    "    print(f\"\\nMemory requirements:\")\n",
    "    print(f\"  Total parameters: {param_count:,}\")\n",
    "    print(f\"  Model size: {param_size:.2f} MB\")\n",
    "    print(f\"  Estimated inference memory: {param_size * 4:.2f} MB (rough estimate)\")\n",
    "\n",
    "# Run the analysis\n",
    "comprehensive_model_analysis(MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a4e918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper medium model...\n",
      "✅ Model loaded!\n",
      "\n",
      "=== BASIC MODEL STRUCTURE ===\n",
      "encoder         | AudioEncoder         |  305,680,384 parameters\n",
      "decoder         | TextDecoder          |  456,641,536 parameters\n",
      "\n",
      "=== ENCODER ANALYSIS ===\n",
      "Encoder type: AudioEncoder\n",
      "Number of encoder blocks: 24\n",
      "  Encoder Block  0: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  1: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  2: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  3: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  4: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  5: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  6: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  7: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  8: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block  9: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 10: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 11: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 12: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 13: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 14: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 15: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 16: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 17: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 18: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 19: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 20: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 21: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 22: 12,595,200 params,  48.05 MB\n",
      "  Encoder Block 23: 12,595,200 params,  48.05 MB\n",
      "Total encoder parameters: 302,284,800\n",
      "\n",
      "=== DECODER ANALYSIS ===\n",
      "Decoder type: TextDecoder\n",
      "Number of decoder blocks: 24\n",
      "  Decoder Block  0: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  1: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  2: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  3: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  4: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  5: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  6: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  7: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  8: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block  9: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 10: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 11: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 12: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 13: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 14: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 15: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 16: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 17: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 18: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 19: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 20: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 21: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 22: 16,794,624 params,  64.07 MB\n",
      "  Decoder Block 23: 16,794,624 params,  64.07 MB\n",
      "Total decoder parameters: 403,070,976\n",
      "\n",
      "=== MEMORY REQUIREMENTS ===\n",
      "Total parameters: 762,321,920\n",
      "Model size (storage): 2908.03 MB\n",
      "Estimated inference RAM: 11632.11 MB\n",
      "Estimated VRAM for GPU: 4362.04 MB\n",
      "\n",
      "=== DISTRIBUTION SUGGESTIONS ===\n",
      "Encoder has 24 blocks - ideal for splitting across machines\n",
      "  2-way split: ~12 blocks per machine\n",
      "  4-way split: ~6 blocks per machine\n",
      "  8-way split: ~3 blocks per machine\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "# Define model size\n",
    "MODEL_SIZE = \"medium\"  # Change to \"tiny\", \"base\", \"small\", \"large\" as needed\n",
    "\n",
    "def analyze_whisper_layers(model_size=MODEL_SIZE):\n",
    "    \"\"\"Complete analysis of Whisper model layers and structure\"\"\"\n",
    "    \n",
    "    print(f\"Loading Whisper {model_size} model...\")\n",
    "    model = whisper.load_model(model_size)\n",
    "    print(\"✅ Model loaded!\\n\")\n",
    "    \n",
    "    # 1. Basic model structure\n",
    "    print(\"=== BASIC MODEL STRUCTURE ===\")\n",
    "    for name, module in model.named_children():\n",
    "        num_params = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"{name:15} | {type(module).__name__:20} | {num_params:>12,} parameters\")\n",
    "    \n",
    "    # 2. Encoder analysis\n",
    "    print(\"\\n=== ENCODER ANALYSIS ===\")\n",
    "    if hasattr(model, 'encoder'):\n",
    "        encoder = model.encoder\n",
    "        print(f\"Encoder type: {type(encoder).__name__}\")\n",
    "        \n",
    "        if hasattr(encoder, 'blocks'):\n",
    "            print(f\"Number of encoder blocks: {len(encoder.blocks)}\")\n",
    "            \n",
    "            # Analyze individual encoder blocks\n",
    "            total_encoder_params = 0\n",
    "            for i, block in enumerate(encoder.blocks):\n",
    "                block_params = sum(p.numel() for p in block.parameters())\n",
    "                total_encoder_params += block_params\n",
    "                block_size_mb = sum(p.numel() * p.element_size() for p in block.parameters()) / (1024 * 1024)\n",
    "                print(f\"  Encoder Block {i:2d}: {block_params:>10,} params, {block_size_mb:>6.2f} MB\")\n",
    "            \n",
    "            print(f\"Total encoder parameters: {total_encoder_params:,}\")\n",
    "        \n",
    "        # Encoder configuration\n",
    "        if hasattr(encoder, 'd_model'):\n",
    "            print(f\"Model dimension (d_model): {encoder.d_model}\")\n",
    "        if hasattr(encoder, 'num_heads'):\n",
    "            print(f\"Number of attention heads: {encoder.num_heads}\")\n",
    "    \n",
    "    # 3. Decoder analysis\n",
    "    print(\"\\n=== DECODER ANALYSIS ===\")\n",
    "    if hasattr(model, 'decoder'):\n",
    "        decoder = model.decoder\n",
    "        print(f\"Decoder type: {type(decoder).__name__}\")\n",
    "        \n",
    "        if hasattr(decoder, 'blocks'):\n",
    "            print(f\"Number of decoder blocks: {len(decoder.blocks)}\")\n",
    "            \n",
    "            # Analyze individual decoder blocks\n",
    "            total_decoder_params = 0\n",
    "            for i, block in enumerate(decoder.blocks):\n",
    "                block_params = sum(p.numel() for p in block.parameters())\n",
    "                total_decoder_params += block_params\n",
    "                block_size_mb = sum(p.numel() * p.element_size() for p in block.parameters()) / (1024 * 1024)\n",
    "                print(f\"  Decoder Block {i:2d}: {block_params:>10,} params, {block_size_mb:>6.2f} MB\")\n",
    "            \n",
    "            print(f\"Total decoder parameters: {total_decoder_params:,}\")\n",
    "    \n",
    "    # 4. Memory requirements\n",
    "    print(\"\\n=== MEMORY REQUIREMENTS ===\")\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    model_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Model size (storage): {model_size_mb:.2f} MB\")\n",
    "    print(f\"Estimated inference RAM: {model_size_mb * 4:.2f} MB\")\n",
    "    print(f\"Estimated VRAM for GPU: {model_size_mb * 1.5:.2f} MB\")\n",
    "    \n",
    "    # 5. Layer distribution suggestions\n",
    "    print(\"\\n=== DISTRIBUTION SUGGESTIONS ===\")\n",
    "    if hasattr(model, 'encoder') and hasattr(model.encoder, 'blocks'):\n",
    "        encoder_blocks = len(model.encoder.blocks)\n",
    "        print(f\"Encoder has {encoder_blocks} blocks - ideal for splitting across machines\")\n",
    "        \n",
    "        # Suggest splits\n",
    "        for num_splits in [2, 4, 8]:\n",
    "            if encoder_blocks >= num_splits:\n",
    "                blocks_per_split = encoder_blocks // num_splits\n",
    "                remainder = encoder_blocks % num_splits\n",
    "                print(f\"  {num_splits}-way split: ~{blocks_per_split} blocks per machine\" + \n",
    "                      (f\" (+{remainder} extra)\" if remainder else \"\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run the complete analysis\n",
    "model = analyze_whisper_layers(MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a059d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Estimated inference memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB (rough estimate)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m comprehensive_model_analysis(\u001b[43mMODEL_SIZE\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MODEL_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "def plan_distributed_setup(model_size=\"medium\", num_machines=2):\n",
    "    \"\"\"Plan how to distribute Whisper across multiple machines\"\"\"\n",
    "    \n",
    "    model = whisper.load_model(model_size)\n",
    "    \n",
    "    print(f\"=== DISTRIBUTION PLAN for Whisper {model_size.upper()} across {num_machines} machines ===\\n\")\n",
    "    \n",
    "    if hasattr(model, 'encoder') and hasattr(model.encoder, 'blocks'):\n",
    "        encoder_blocks = model.encoder.blocks\n",
    "        total_blocks = len(encoder_blocks)\n",
    "        \n",
    "        blocks_per_machine = total_blocks // num_machines\n",
    "        remainder = total_blocks % num_machines\n",
    "        \n",
    "        print(f\"Total encoder blocks: {total_blocks}\")\n",
    "        print(f\"Target: {num_machines} machines\")\n",
    "        print(f\"Base blocks per machine: {blocks_per_machine}\")\n",
    "        if remainder:\n",
    "            print(f\"Extra blocks to distribute: {remainder}\")\n",
    "        \n",
    "        print(\"\\nRecommended distribution:\")\n",
    "        current_block = 0\n",
    "        for machine in range(num_machines):\n",
    "            machine_blocks = blocks_per_machine\n",
    "            if machine < remainder:\n",
    "                machine_blocks += 1\n",
    "            \n",
    "            block_range = f\"{current_block}-{current_block + machine_blocks - 1}\"\n",
    "            \n",
    "            # Calculate parameters for this machine's blocks\n",
    "            machine_params = 0\n",
    "            for i in range(current_block, current_block + machine_blocks):\n",
    "                machine_params += sum(p.numel() for p in encoder_blocks[i].parameters())\n",
    "            \n",
    "            machine_size_mb = machine_params * 4 / (1024 * 1024)  # approx size in MB\n",
    "            \n",
    "            print(f\"  Machine {machine}: Blocks {block_range} | {machine_params:,} params | ~{machine_size_mb:.1f} MB\")\n",
    "            current_block += machine_blocks\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test the distribution planning\n",
    "plan_distributed_setup(MODEL_SIZE, num_machines=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
